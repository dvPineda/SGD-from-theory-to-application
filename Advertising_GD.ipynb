{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "# ==================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import random\n",
    "# =================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read 'Advertising' dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>radio</th>\n",
       "      <th>newspaper</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TV  radio  newspaper  sales\n",
       "0  230.1   37.8       69.2   22.1\n",
       "1   44.5   39.3       45.1   10.4\n",
       "2   17.2   45.9       69.3    9.3\n",
       "3  151.5   41.3       58.5   18.5\n",
       "4  180.8   10.8       58.4   12.9"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./datasets/Advertising.csv')\n",
    "\n",
    "df.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instance X and target Y (both normalized)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['sales'], axis=1) # features\n",
    "Y = df['sales'] # target\n",
    "\n",
    "# standardize the data\n",
    "Y = np.array((Y-Y.mean())/Y.std())\n",
    "X = X.apply(lambda x:(x-x.mean())/x.std(),axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initialize bias and weights to random values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias: 0.055419667084502966, Weights: [0.74237888 0.9057786  0.49943938]\n"
     ]
    }
   ],
   "source": [
    "def initialize(dim):\n",
    "  b = random.random()\n",
    "  weights = np.random.rand(dim) \n",
    "  return b, weights\n",
    "\n",
    "b,weights=initialize(3)\n",
    "print(f'Bias: {b}, Weights: {weights}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predict Y by a linear combination of X and weights + bias aggregation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.54668336,  0.48064392,  1.20220425,  1.83518237,  0.22549212,\n",
       "        1.44244547, -0.29884259, -0.83488461, -3.11061663, -0.96357452])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict_Y(b, weights, X):\n",
    "  return b + np.dot(X, weights) # y = b + w_1*x_1 + w_2*x_2 + ...\n",
    "\n",
    "Y_hat=predict_Y(b, weights, X)\n",
    "Y_hat[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculate the error by MSE between predicted Y and target Y**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost: 0.6237334982826248\n"
     ]
    }
   ],
   "source": [
    "def compute_cost(Y, Y_hat) -> float:\n",
    "    ''' Performs Mean Squared Error (MSE) cost function between the actual values and the predicted values. '''\n",
    "    Y_resid = Y - Y_hat\n",
    "    return np.sum(np.square(Y_resid)) / len(Y_resid) # MSE = sum((y - y_hat)^2) / n\n",
    "\n",
    "Y_hat = predict_Y(b, weights, X)\n",
    "cost = compute_cost(Y, Y_hat)\n",
    "\n",
    "print(f'Cost: {cost}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Perform gradient descent by updating weights and bias**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before update\n",
      " Bias: 0.055419667084502966,\n",
      "Weights: [0.74237888 0.9057786  0.49943938]\n",
      "\n",
      "bias update for step: 0.0011083933416900591, \n",
      "weights update for step: [0.00075801 0.01088725 0.01261529]\n",
      "--------------------------\n",
      "After update\n",
      " Bias: 0.05431127374281291,\n",
      "Weights: [0.74162087 0.89489134 0.48682409]\n"
     ]
    }
   ],
   "source": [
    "def update_parameters(x, y, y_hat, b_0, w_0, learning_rate):\n",
    "  db = (np.sum(y_hat - y) * 2) / len(y)\n",
    "  dw = (np.dot((y_hat - y), x) * 2) / len(y)\n",
    "\n",
    "  print(f'\\nbias update for step: {db * learning_rate}, \\nweights update for step: {dw * learning_rate}')\n",
    "  next_b = b_0 - learning_rate * db # b0 - eta * nabla_b\n",
    "  next_w = w_0 - learning_rate * dw # w0 - eta * nabla_w\n",
    "  return next_b,next_w\n",
    "\n",
    "print(f'Before update\\n Bias: {b},\\nWeights: {weights}')\n",
    "\n",
    "Y_hat = predict_Y(b,weights,X)\n",
    "b,weights = update_parameters(X,Y,Y_hat,b,weights,0.01)\n",
    "\n",
    "print(\"--------------------------\")\n",
    "\n",
    "print(f'After update\\n Bias: {b},\\nWeights: {weights}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bias update for step: 0.013082760263392189, \n",
      "weights update for step: [-0.00666851  0.00384404  0.0069121 ]\n",
      "\n",
      "bias update for step: 0.012821105058124345, \n",
      "weights update for step: [-0.00654779  0.00372611  0.00675498]\n",
      "\n",
      "bias update for step: 0.012564682956961858, \n",
      "weights update for step: [-0.00642917  0.00361151  0.00660168]\n",
      "\n",
      "bias update for step: 0.01231338929782262, \n",
      "weights update for step: [-0.00631261  0.00350013  0.00645211]\n",
      "\n",
      "bias update for step: 0.012067121511866166, \n",
      "weights update for step: [-0.00619808  0.0033919   0.00630616]\n",
      "\n",
      "bias update for step: 0.011825779081628844, \n",
      "weights update for step: [-0.00608555  0.00328672  0.00616375]\n",
      "\n",
      "bias update for step: 0.011589263499996267, \n",
      "weights update for step: [-0.00597498  0.00318452  0.00602479]\n",
      "\n",
      "bias update for step: 0.01135747822999634, \n",
      "weights update for step: [-0.00586634  0.00308521  0.0058892 ]\n",
      "\n",
      "bias update for step: 0.011130328665396413, \n",
      "weights update for step: [-0.00575961  0.00298871  0.00575687]\n",
      "\n",
      "bias update for step: 0.010907722092088486, \n",
      "weights update for step: [-0.00565474  0.00289495  0.00562774]\n",
      "\n",
      "bias update for step: 0.010689567650246716, \n",
      "weights update for step: [-0.00555171  0.00280385  0.00550173]\n",
      "\n",
      "bias update for step: 0.01047577629724178, \n",
      "weights update for step: [-0.00545049  0.00271534  0.00537874]\n",
      "\n",
      "bias update for step: 0.010266260771296944, \n",
      "weights update for step: [-0.00535105  0.00262935  0.00525872]\n",
      "\n",
      "bias update for step: 0.010060935555871007, \n",
      "weights update for step: [-0.00525336  0.00254581  0.00514157]\n",
      "\n",
      "bias update for step: 0.009859716844753584, \n",
      "weights update for step: [-0.00515739  0.00246464  0.00502724]\n",
      "\n",
      "bias update for step: 0.009662522507858514, \n",
      "weights update for step: [-0.00506312  0.0023858   0.00491564]\n",
      "\n",
      "bias update for step: 0.009469272057701343, \n",
      "weights update for step: [-0.00497051  0.0023092   0.00480672]\n",
      "\n",
      "bias update for step: 0.009279886616547318, \n",
      "weights update for step: [-0.00487953  0.0022348   0.00470039]\n",
      "\n",
      "bias update for step: 0.00909428888421637, \n",
      "weights update for step: [-0.00479016  0.00216253  0.00459661]\n",
      "\n",
      "bias update for step: 0.008912403106532045, \n",
      "weights update for step: [-0.00470238  0.00209233  0.0044953 ]\n",
      "\n",
      "bias update for step: 0.008734155044401401, \n",
      "weights update for step: [-0.00461615  0.00202414  0.0043964 ]\n",
      "\n",
      "bias update for step: 0.008559471943513376, \n",
      "weights update for step: [-0.00453145  0.00195792  0.00429985]\n",
      "\n",
      "bias update for step: 0.008388282504643107, \n",
      "weights update for step: [-0.00444826  0.0018936   0.00420559]\n",
      "\n",
      "bias update for step: 0.008220516854550245, \n",
      "weights update for step: [-0.00436655  0.00183113  0.00411357]\n",
      "\n",
      "bias update for step: 0.008056106517459242, \n",
      "weights update for step: [-0.00428629  0.00177047  0.00402373]\n",
      "\n",
      "bias update for step: 0.007894984387110057, \n",
      "weights update for step: [-0.00420746  0.00171155  0.00393602]\n",
      "\n",
      "bias update for step: 0.007737084699367855, \n",
      "weights update for step: [-0.00413003  0.00165435  0.00385037]\n",
      "\n",
      "bias update for step: 0.007582343005380497, \n",
      "weights update for step: [-0.00405399  0.0015988   0.00376675]\n",
      "\n",
      "bias update for step: 0.007430696145272887, \n",
      "weights update for step: [-0.0039793   0.00154486  0.00368509]\n",
      "\n",
      "bias update for step: 0.00728208222236743, \n",
      "weights update for step: [-0.00390596  0.00149249  0.00360536]\n",
      "\n",
      "bias update for step: 0.0071364405779200816, \n",
      "weights update for step: [-0.00383392  0.00144164  0.0035275 ]\n",
      "\n",
      "bias update for step: 0.006993711766361679, \n",
      "weights update for step: [-0.00376317  0.00139228  0.00345147]\n",
      "\n",
      "bias update for step: 0.006853837531034447, \n",
      "weights update for step: [-0.0036937   0.00134436  0.00337721]\n",
      "\n",
      "bias update for step: 0.0067167607804137575, \n",
      "weights update for step: [-0.00362546  0.00129784  0.0033047 ]\n",
      "\n",
      "bias update for step: 0.006582425564805482, \n",
      "weights update for step: [-0.00355846  0.00125268  0.00323387]\n",
      "\n",
      "bias update for step: 0.006450777053509371, \n",
      "weights update for step: [-0.00349266  0.00120884  0.0031647 ]\n",
      "\n",
      "bias update for step: 0.006321761512439184, \n",
      "weights update for step: [-0.00342804  0.00116629  0.00309715]\n",
      "\n",
      "bias update for step: 0.006195326282190401, \n",
      "weights update for step: [-0.00336458  0.001125    0.00303116]\n",
      "\n",
      "bias update for step: 0.006071419756546593, \n",
      "weights update for step: [-0.00330227  0.00108492  0.0029667 ]\n",
      "\n",
      "bias update for step: 0.005949991361415663, \n",
      "weights update for step: [-0.00324109  0.00104603  0.00290374]\n",
      "\n",
      "bias update for step: 0.005830991534187349, \n",
      "weights update for step: [-0.003181    0.00100828  0.00284224]\n",
      "\n",
      "bias update for step: 0.0057143717035036, \n",
      "weights update for step: [-0.003122    0.00097166  0.00278216]\n",
      "\n",
      "bias update for step: 0.005600084269433529, \n",
      "weights update for step: [-0.00306407  0.00093613  0.00272347]\n",
      "\n",
      "bias update for step: 0.0054880825840448585, \n",
      "weights update for step: [-0.00300719  0.00090165  0.00266613]\n",
      "\n",
      "bias update for step: 0.005378320932363962, \n",
      "weights update for step: [-0.00295133  0.0008682   0.00261011]\n",
      "\n",
      "bias update for step: 0.005270754513716682, \n",
      "weights update for step: [-0.00289649  0.00083575  0.00255538]\n",
      "\n",
      "bias update for step: 0.005165339423442349, \n",
      "weights update for step: [-0.00284264  0.00080427  0.0025019 ]\n",
      "\n",
      "bias update for step: 0.005062032634973503, \n",
      "weights update for step: [-0.00278977  0.00077373  0.00244965]\n",
      "\n",
      "bias update for step: 0.004960791982274032, \n",
      "weights update for step: [-0.00273786  0.00074412  0.0023986 ]\n",
      "\n",
      "bias update for step: 0.004861576142628552, \n",
      "weights update for step: [-0.00268689  0.00071539  0.00234871]\n",
      "\n",
      "bias update for step: 0.00476434461977598, \n",
      "weights update for step: [-0.00263685  0.00068754  0.00229996]\n",
      "\n",
      "bias update for step: 0.0046690577273804604, \n",
      "weights update for step: [-0.00258772  0.00066052  0.00225231]\n",
      "\n",
      "bias update for step: 0.0045756765728328505, \n",
      "weights update for step: [-0.00253949  0.00063433  0.00220576]\n",
      "\n",
      "bias update for step: 0.004484163041376194, \n",
      "weights update for step: [-0.00249213  0.00060893  0.00216025]\n",
      "\n",
      "bias update for step: 0.004394479780548671, \n",
      "weights update for step: [-0.00244563  0.00058431  0.00211578]\n",
      "\n",
      "bias update for step: 0.004306590184937697, \n",
      "weights update for step: [-0.00239999  0.00056044  0.00207232]\n",
      "\n",
      "bias update for step: 0.004220458381238943, \n",
      "weights update for step: [-0.00235518  0.0005373   0.00202984]\n",
      "\n",
      "bias update for step: 0.004136049213614165, \n",
      "weights update for step: [-0.00231118  0.00051488  0.00198831]\n",
      "\n",
      "bias update for step: 0.004053328229341881, \n",
      "weights update for step: [-0.00226799  0.00049314  0.00194772]\n",
      "\n",
      "bias update for step: 0.003972261664755044, \n",
      "weights update for step: [-0.00222559  0.00047208  0.00190804]\n",
      "\n",
      "bias update for step: 0.0038928164314599428, \n",
      "weights update for step: [-0.00218397  0.00045166  0.00186926]\n",
      "\n",
      "bias update for step: 0.0038149601028307444, \n",
      "weights update for step: [-0.00214311  0.00043188  0.00183134]\n",
      "\n",
      "bias update for step: 0.003738660900774129, \n",
      "weights update for step: [-0.002103    0.00041272  0.00179427]\n",
      "\n",
      "bias update for step: 0.0036638876827586463, \n",
      "weights update for step: [-0.00206362  0.00039416  0.00175802]\n",
      "\n",
      "bias update for step: 0.0035906099291034737, \n",
      "weights update for step: [-0.00202497  0.00037618  0.00172259]\n",
      "\n",
      "bias update for step: 0.0035187977305214044, \n",
      "weights update for step: [-0.00198702  0.00035876  0.00168794]\n",
      "\n",
      "bias update for step: 0.0034484217759109754, \n",
      "weights update for step: [-0.00194977  0.0003419   0.00165406]\n",
      "\n",
      "bias update for step: 0.0033794533403927554, \n",
      "weights update for step: [-0.00191321  0.00032556  0.00162093]\n",
      "\n",
      "bias update for step: 0.0033118642735849016, \n",
      "weights update for step: [-0.00187732  0.00030975  0.00158854]\n",
      "\n",
      "bias update for step: 0.0032456269881132034, \n",
      "weights update for step: [-0.00184209  0.00029444  0.00155686]\n",
      "\n",
      "bias update for step: 0.003180714448350939, \n",
      "weights update for step: [-0.00180751  0.00027962  0.00152588]\n",
      "\n",
      "bias update for step: 0.003117100159383921, \n",
      "weights update for step: [-0.00177356  0.00026527  0.00149558]\n",
      "\n",
      "bias update for step: 0.0030547581561962416, \n",
      "weights update for step: [-0.00174025  0.00025139  0.00146595]\n",
      "\n",
      "bias update for step: 0.0029936629930723165, \n",
      "weights update for step: [-0.00170754  0.00023795  0.00143697]\n",
      "\n",
      "bias update for step: 0.0029337897332108705, \n",
      "weights update for step: [-0.00167544  0.00022496  0.00140862]\n",
      "\n",
      "bias update for step: 0.002875113938546653, \n",
      "weights update for step: [-0.00164393  0.00021238  0.00138089]\n",
      "\n",
      "bias update for step: 0.00281761165977572, \n",
      "weights update for step: [-0.00161301  0.00020022  0.00135377]\n",
      "\n",
      "bias update for step: 0.0027612594265802055, \n",
      "weights update for step: [-0.00158265  0.00018845  0.00132724]\n",
      "\n",
      "bias update for step: 0.002706034238048601, \n",
      "weights update for step: [-0.00155286  0.00017708  0.00130128]\n",
      "\n",
      "bias update for step: 0.0026519135532876294, \n",
      "weights update for step: [-0.00152362  0.00016608  0.00127589]\n",
      "\n",
      "bias update for step: 0.002598875282221877, \n",
      "weights update for step: [-0.00149492  0.00015544  0.00125105]\n",
      "\n",
      "bias update for step: 0.0025468977765774393, \n",
      "weights update for step: [-0.00146675  0.00014516  0.00122674]\n",
      "\n",
      "bias update for step: 0.0024959598210458913, \n",
      "weights update for step: [-0.0014391   0.00013523  0.00120296]\n",
      "\n",
      "bias update for step: 0.002446040624624973, \n",
      "weights update for step: [-0.00141197  0.00012563  0.00117969]\n",
      "\n",
      "bias update for step: 0.0023971198121324738, \n",
      "weights update for step: [-0.00138533  0.00011636  0.00115692]\n",
      "\n",
      "bias update for step: 0.002349177415889824, \n",
      "weights update for step: [-0.0013592   0.0001074   0.00113464]\n",
      "\n",
      "bias update for step: 0.0023021938675720274, \n",
      "weights update for step: [-1.33354603e-03  9.87515272e-05  1.11283501e-03]\n",
      "\n",
      "bias update for step: 0.002256149990220587, \n",
      "weights update for step: [-1.30837066e-03  9.03990853e-05  1.09149702e-03]\n",
      "\n",
      "bias update for step: 0.002211026990416175, \n",
      "weights update for step: [-1.28366312e-03  8.23357600e-05  1.07061414e-03]\n",
      "\n",
      "bias update for step: 0.002166806450607851, \n",
      "weights update for step: [-1.25941492e-03  7.45531012e-05  1.05017579e-03]\n",
      "\n",
      "bias update for step: 0.0021234703215956942, \n",
      "weights update for step: [-1.23561773e-03  6.70428922e-05  1.03017167e-03]\n",
      "\n",
      "bias update for step: 0.00208100091516378, \n",
      "weights update for step: [-1.21226337e-03  5.97971433e-05  1.01059172e-03]\n",
      "\n",
      "bias update for step: 0.0020393808968605055, \n",
      "weights update for step: [-1.18934378e-03  5.28080856e-05  9.91426155e-04]\n",
      "\n",
      "bias update for step: 0.001998593278923294, \n",
      "weights update for step: [-1.16685106e-03  4.60681653e-05  9.72665392e-04]\n",
      "\n",
      "bias update for step: 0.0019586214133448287, \n",
      "weights update for step: [-1.14477745e-03  3.95700376e-05  9.54300106e-04]\n",
      "\n",
      "bias update for step: 0.001919448985077932, \n",
      "weights update for step: [-1.12311531e-03  3.33065612e-05  9.36321197e-04]\n",
      "\n",
      "bias update for step: 0.0018810600053763744, \n",
      "weights update for step: [-1.10185715e-03  2.72707925e-05  9.18719785e-04]\n",
      "\n",
      "bias update for step: 0.0018434388052688462, \n",
      "weights update for step: [-1.08099561e-03  2.14559808e-05  9.01487208e-04]\n",
      "\n",
      "bias update for step: 0.0018065700291634696, \n",
      "weights update for step: [-1.06052344e-03  1.58555624e-05  8.84615018e-04]\n",
      "\n",
      "bias update for step: 0.0017704386285802007, \n",
      "weights update for step: [-1.04043353e-03  1.04631562e-05  8.68094971e-04]\n",
      "\n",
      "bias update for step: 0.0017350298560085966, \n",
      "weights update for step: [-1.02071892e-03  5.27255826e-06  8.51919024e-04]\n",
      "\n",
      "bias update for step: 0.0017003292588884248, \n",
      "weights update for step: [-1.00137272e-03  2.77737081e-07  8.36079330e-04]\n",
      "\n",
      "bias update for step: 0.001666322673710656, \n",
      "weights update for step: [-9.82388214e-04 -4.52717090e-06  8.20568235e-04]\n",
      "\n",
      "bias update for step: 0.0016329962202364424, \n",
      "weights update for step: [-9.63758771e-04 -9.14786598e-06  8.05378267e-04]\n",
      "\n",
      "bias update for step: 0.0016003362958317132, \n",
      "weights update for step: [-9.45477891e-04 -1.35898896e-05  7.90502140e-04]\n",
      "\n",
      "bias update for step: 0.0015683295699150798, \n",
      "weights update for step: [-9.27539186e-04 -1.78586287e-05  7.75932741e-04]\n",
      "\n",
      "bias update for step: 0.0015369629785167776, \n",
      "weights update for step: [-9.09936382e-04 -2.19593199e-05  7.61663131e-04]\n",
      "\n",
      "bias update for step: 0.0015062237189464426, \n",
      "weights update for step: [-8.92663314e-04 -2.58970533e-05  7.47686540e-04]\n",
      "\n",
      "bias update for step: 0.0014760992445675134, \n",
      "weights update for step: [-8.75713930e-04 -2.96767772e-05  7.33996358e-04]\n",
      "\n",
      "bias update for step: 0.0014465772596761633, \n",
      "weights update for step: [-8.59082283e-04 -3.33033009e-05  7.20586139e-04]\n",
      "\n",
      "bias update for step: 0.00141764571448264, \n",
      "weights update for step: [-8.42762534e-04 -3.67812996e-05  7.07449589e-04]\n",
      "\n",
      "bias update for step: 0.0013892928001929875, \n",
      "weights update for step: [-8.26748945e-04 -4.01153170e-05  6.94580568e-04]\n",
      "\n",
      "bias update for step: 0.0013615069441891279, \n",
      "weights update for step: [-8.11035883e-04 -4.33097697e-05  6.81973082e-04]\n",
      "\n",
      "bias update for step: 0.0013342768053053447, \n",
      "weights update for step: [-7.95617815e-04 -4.63689502e-05  6.69621282e-04]\n",
      "\n",
      "bias update for step: 0.0013075912691992383, \n",
      "weights update for step: [-7.80489305e-04 -4.92970304e-05  6.57519459e-04]\n",
      "\n",
      "bias update for step: 0.0012814394438152529, \n",
      "weights update for step: [-7.65645017e-04 -5.20980648e-05  6.45662041e-04]\n",
      "\n",
      "bias update for step: 0.0012558106549389481, \n",
      "weights update for step: [-7.51079708e-04 -5.47759940e-05  6.34043590e-04]\n",
      "\n",
      "bias update for step: 0.001230694441840169, \n",
      "weights update for step: [-7.36788231e-04 -5.73346473e-05  6.22658798e-04]\n",
      "\n",
      "bias update for step: 0.0012060805530033666, \n",
      "weights update for step: [-7.22765529e-04 -5.97777462e-05  6.11502482e-04]\n",
      "\n",
      "bias update for step: 0.0011819589419432982, \n",
      "weights update for step: [-7.09006638e-04 -6.21089071e-05  6.00569584e-04]\n",
      "\n",
      "bias update for step: 0.0011583197631044326, \n",
      "weights update for step: [-6.95506682e-04 -6.43316441e-05  5.89855168e-04]\n",
      "\n",
      "bias update for step: 0.001135153367842344, \n",
      "weights update for step: [-6.82260873e-04 -6.64493721e-05  5.79354413e-04]\n",
      "\n",
      "bias update for step: 0.0011124503004854977, \n",
      "weights update for step: [-6.69264508e-04 -6.84654091e-05  5.69062615e-04]\n",
      "\n",
      "bias update for step: 0.001090201294475787, \n",
      "weights update for step: [-6.56512969e-04 -7.03829791e-05  5.58975178e-04]\n",
      "\n",
      "bias update for step: 0.001068397268586271, \n",
      "weights update for step: [-6.44001724e-04 -7.22052147e-05  5.49087620e-04]\n",
      "\n",
      "bias update for step: 0.0010470293232145455, \n",
      "weights update for step: [-6.31726318e-04 -7.39351595e-05  5.39395561e-04]\n",
      "\n",
      "bias update for step: 0.0010260887367502549, \n",
      "weights update for step: [-6.19682381e-04 -7.55757703e-05  5.29894726e-04]\n",
      "\n",
      "bias update for step: 0.0010055669620152503, \n",
      "weights update for step: [-6.07865618e-04 -7.71299201e-05  5.20580941e-04]\n",
      "\n",
      "bias update for step: 0.0009854556227749454, \n",
      "weights update for step: [-5.96271814e-04 -7.86003995e-05  5.11450132e-04]\n",
      "\n",
      "bias update for step: 0.0009657465103194457, \n",
      "weights update for step: [-5.84896830e-04 -7.99899200e-05  5.02498318e-04]\n",
      "\n",
      "bias update for step: 0.0009464315801130574, \n",
      "weights update for step: [-5.73736602e-04 -8.13011152e-05  4.93721613e-04]\n",
      "\n",
      "bias update for step: 0.0009275029485107962, \n",
      "weights update for step: [-5.62787137e-04 -8.25365434e-05  4.85116224e-04]\n",
      "\n",
      "bias update for step: 0.00090895288954058, \n",
      "weights update for step: [-5.52044519e-04 -8.36986899e-05  4.76678444e-04]\n",
      "\n",
      "bias update for step: 0.000890773831749768, \n",
      "weights update for step: [-5.41504900e-04 -8.47899683e-05  4.68404655e-04]\n",
      "\n",
      "bias update for step: 0.0008729583551147727, \n",
      "weights update for step: [-5.31164502e-04 -8.58127232e-05  4.60291324e-04]\n",
      "\n",
      "bias update for step: 0.0008554991880124781, \n",
      "weights update for step: [-5.21019616e-04 -8.67692315e-05  4.52334998e-04]\n",
      "\n",
      "bias update for step: 0.0008383892042522287, \n",
      "weights update for step: [-5.11066601e-04 -8.76617047e-05  4.44532307e-04]\n",
      "\n",
      "bias update for step: 0.0008216214201671834, \n",
      "weights update for step: [-5.01301882e-04 -8.84922904e-05  4.36879958e-04]\n",
      "\n",
      "bias update for step: 0.0008051889917638405, \n",
      "weights update for step: [-4.91721948e-04 -8.92630742e-05  4.29374736e-04]\n",
      "\n",
      "bias update for step: 0.0007890852119285627, \n",
      "weights update for step: [-4.82323354e-04 -8.99760814e-05  4.22013501e-04]\n",
      "\n",
      "bias update for step: 0.000773303507689992, \n",
      "weights update for step: [-4.73102716e-04 -9.06332785e-05  4.14793183e-04]\n",
      "\n",
      "bias update for step: 0.0007578374375361919, \n",
      "weights update for step: [-4.64056712e-04 -9.12365752e-05  4.07710786e-04]\n",
      "\n",
      "bias update for step: 0.0007426806887854686, \n",
      "weights update for step: [-4.55182082e-04 -9.17878254e-05  4.00763383e-04]\n",
      "\n",
      "bias update for step: 0.0007278270750097585, \n",
      "weights update for step: [-4.46475624e-04 -9.22888292e-05  3.93948113e-04]\n",
      "\n",
      "bias update for step: 0.0007132705335095638, \n",
      "weights update for step: [-4.37934195e-04 -9.27413341e-05  3.87262183e-04]\n",
      "\n",
      "bias update for step: 0.0006990051228393723, \n",
      "weights update for step: [-4.29554710e-04 -9.31470368e-05  3.80702862e-04]\n",
      "\n",
      "bias update for step: 0.0006850250203825857, \n",
      "weights update for step: [-4.21334140e-04 -9.35075841e-05  3.74267485e-04]\n",
      "\n",
      "bias update for step: 0.0006713245199749332, \n",
      "weights update for step: [-4.13269512e-04 -9.38245747e-05  3.67953446e-04]\n",
      "\n",
      "bias update for step: 0.0006578980295754343, \n",
      "weights update for step: [-4.05357906e-04 -9.40995603e-05  3.61758198e-04]\n",
      "\n",
      "bias update for step: 0.0006447400689839263, \n",
      "weights update for step: [-3.97596457e-04 -9.43340469e-05  3.55679255e-04]\n",
      "\n",
      "bias update for step: 0.000631845267604248, \n",
      "weights update for step: [-3.89982353e-04 -9.45294964e-05  3.49714186e-04]\n",
      "\n",
      "bias update for step: 0.0006192083622521632, \n",
      "weights update for step: [-3.82512832e-04 -9.46873272e-05  3.43860615e-04]\n",
      "\n",
      "bias update for step: 0.0006068241950071195, \n",
      "weights update for step: [-3.75185183e-04 -9.48089160e-05  3.38116223e-04]\n",
      "\n",
      "bias update for step: 0.0005946877111069774, \n",
      "weights update for step: [-3.67996747e-04 -9.48955985e-05  3.32478740e-04]\n",
      "\n",
      "bias update for step: 0.0005827939568848368, \n",
      "weights update for step: [-3.60944910e-04 -9.49486710e-05  3.26945951e-04]\n",
      "\n",
      "bias update for step: 0.0005711380777471407, \n",
      "weights update for step: [-3.54027111e-04 -9.49693911e-05  3.21515688e-04]\n",
      "\n",
      "bias update for step: 0.0005597153161921983, \n",
      "weights update for step: [-3.47240831e-04 -9.49589787e-05  3.16185836e-04]\n",
      "\n",
      "bias update for step: 0.0005485210098683533, \n",
      "weights update for step: [-3.40583601e-04 -9.49186177e-05  3.10954324e-04]\n",
      "\n",
      "bias update for step: 0.0005375505896709864, \n",
      "weights update for step: [-3.34052997e-04 -9.48494561e-05  3.05819130e-04]\n",
      "\n",
      "bias update for step: 0.0005267995778775668, \n",
      "weights update for step: [-3.27646639e-04 -9.47526077e-05  3.00778277e-04]\n",
      "\n",
      "bias update for step: 0.0005162635863200156, \n",
      "weights update for step: [-3.21362190e-04 -9.46291527e-05  2.95829833e-04]\n",
      "\n",
      "bias update for step: 0.0005059383145936157, \n",
      "weights update for step: [-3.15197358e-04 -9.44801389e-05  2.90971908e-04]\n",
      "\n",
      "bias update for step: 0.000495819548301743, \n",
      "weights update for step: [-3.09149892e-04 -9.43065822e-05  2.86202657e-04]\n",
      "\n",
      "bias update for step: 0.00048590315733570847, \n",
      "weights update for step: [-3.03217584e-04 -9.41094679e-05  2.81520273e-04]\n",
      "\n",
      "bias update for step: 0.0004761850941889939, \n",
      "weights update for step: [-2.97398265e-04 -9.38897514e-05  2.76922993e-04]\n",
      "\n",
      "bias update for step: 0.0004666613923052145, \n",
      "weights update for step: [-2.91689808e-04 -9.36483587e-05  2.72409090e-04]\n",
      "\n",
      "bias update for step: 0.00045732816445911013, \n",
      "weights update for step: [-2.86090124e-04 -9.33861880e-05  2.67976877e-04]\n",
      "\n",
      "bias update for step: 0.00044818160116992767, \n",
      "weights update for step: [-2.80597163e-04 -9.31041097e-05  2.63624706e-04]\n",
      "\n",
      "bias update for step: 0.000439217969146529, \n",
      "weights update for step: [-2.75208914e-04 -9.28029676e-05  2.59350963e-04]\n",
      "\n",
      "bias update for step: 0.000430433609763599, \n",
      "weights update for step: [-2.69923402e-04 -9.24835796e-05  2.55154071e-04]\n",
      "\n",
      "bias update for step: 0.0004218249375683264, \n",
      "weights update for step: [-2.64738688e-04 -9.21467381e-05  2.51032488e-04]\n",
      "\n",
      "bias update for step: 0.0004133884388169598, \n",
      "weights update for step: [-2.59652872e-04 -9.17932113e-05  2.46984707e-04]\n",
      "\n",
      "bias update for step: 0.0004051206700406204, \n",
      "weights update for step: [-2.54664085e-04 -9.14237434e-05  2.43009252e-04]\n",
      "\n",
      "bias update for step: 0.0003970182566398081, \n",
      "weights update for step: [-2.49770498e-04 -9.10390554e-05  2.39104681e-04]\n",
      "\n",
      "bias update for step: 0.0003890778915070123, \n",
      "weights update for step: [-2.44970310e-04 -9.06398459e-05  2.35269584e-04]\n",
      "\n",
      "bias update for step: 0.0003812963336768721, \n",
      "weights update for step: [-2.40261758e-04 -9.02267916e-05  2.31502581e-04]\n",
      "\n",
      "bias update for step: 0.0003736704070033345, \n",
      "weights update for step: [-2.35643111e-04 -8.98005478e-05  2.27802323e-04]\n",
      "\n",
      "bias update for step: 0.0003661969988632675, \n",
      "weights update for step: [-2.31112668e-04 -8.93617493e-05  2.24167490e-04]\n",
      "\n",
      "bias update for step: 0.00035887305888600236, \n",
      "weights update for step: [-2.26668762e-04 -8.89110108e-05  2.20596791e-04]\n",
      "\n",
      "bias update for step: 0.0003516955977082821, \n",
      "weights update for step: [-2.22309756e-04 -8.84489274e-05  2.17088963e-04]\n",
      "\n",
      "bias update for step: 0.0003446616857541163, \n",
      "weights update for step: [-2.18034044e-04 -8.79760753e-05  2.13642771e-04]\n",
      "\n",
      "bias update for step: 0.0003377684520390342, \n",
      "weights update for step: [-2.13840050e-04 -8.74930123e-05  2.10257006e-04]\n",
      "\n",
      "bias update for step: 0.0003310130829982544, \n",
      "weights update for step: [-2.09726226e-04 -8.70002782e-05  2.06930486e-04]\n",
      "\n",
      "bias update for step: 0.00032439282133828916, \n",
      "weights update for step: [-2.05691055e-04 -8.64983956e-05  2.03662054e-04]\n",
      "\n",
      "bias update for step: 0.00031790496491152295, \n",
      "weights update for step: [-2.01733047e-04 -8.59878700e-05  2.00450578e-04]\n",
      "\n",
      "bias update for step: 0.00031154686561329236, \n",
      "weights update for step: [-1.97850739e-04 -8.54691907e-05  1.97294951e-04]\n",
      "\n",
      "bias update for step: 0.00030531592830102683, \n",
      "weights update for step: [-1.94042698e-04 -8.49428309e-05  1.94194090e-04]\n",
      "\n",
      "bias update for step: 0.0002992096097350059, \n",
      "weights update for step: [-1.90307515e-04 -8.44092483e-05  1.91146934e-04]\n",
      "\n",
      "bias update for step: 0.00029322541754030613, \n",
      "weights update for step: [-1.86643810e-04 -8.38688856e-05  1.88152446e-04]\n",
      "\n",
      "bias update for step: 0.0002873609091895002, \n",
      "weights update for step: [-1.83050226e-04 -8.33221710e-05  1.85209611e-04]\n",
      "\n",
      "bias update for step: 0.00028161369100570985, \n",
      "weights update for step: [-1.79525433e-04 -8.27695183e-05  1.82317434e-04]\n",
      "\n",
      "bias update for step: 0.0002759814171855954, \n",
      "weights update for step: [-1.76068126e-04 -8.22113277e-05  1.79474944e-04]\n",
      "\n",
      "bias update for step: 0.0002704617888418835, \n",
      "weights update for step: [-1.72677024e-04 -8.16479858e-05  1.76681188e-04]\n",
      "\n",
      "bias update for step: 0.00026505255306504656, \n",
      "weights update for step: [-1.69350869e-04 -8.10798665e-05  1.73935236e-04]\n",
      "\n",
      "bias update for step: 0.00025975150200374463, \n",
      "weights update for step: [-1.66088430e-04 -8.05073307e-05  1.71236176e-04]\n",
      "\n",
      "bias update for step: 0.00025455647196366945, \n",
      "weights update for step: [-1.62888495e-04 -7.99307273e-05  1.68583114e-04]\n",
      "\n",
      "bias update for step: 0.0002494653425243964, \n",
      "weights update for step: [-1.59749876e-04 -7.93503933e-05  1.65975178e-04]\n",
      "\n",
      "bias update for step: 0.0002444760356739087, \n",
      "weights update for step: [-1.56671410e-04 -7.87666539e-05  1.63411513e-04]\n",
      "\n",
      "bias update for step: 0.0002395865149604304, \n",
      "weights update for step: [-1.53651951e-04 -7.81798233e-05  1.60891280e-04]\n",
      "\n",
      "bias update for step: 0.00023479478466122253, \n",
      "weights update for step: [-1.50690378e-04 -7.75902047e-05  1.58413662e-04]\n",
      "Final Bias: 0.011504944448399838, Weights: [0.74542442 0.52918778 0.00652302]\n"
     ]
    }
   ],
   "source": [
    "def run_gradient_descent(X, Y, learning_rate, num_iterations):\n",
    "  \n",
    "  b, weights = initialize(X.shape[1])\n",
    "  iter_num = 0\n",
    "  gd_iterations_df = pd.DataFrame(columns=['iteration', 'cost']) # to store the cost at each iteration\n",
    "  result_idx = 0\n",
    "\n",
    "  for _ in range(num_iterations):\n",
    "    Y_hat = predict_Y(b, weights, X)\n",
    "    this_cost = compute_cost(Y, Y_hat)\n",
    "    prev_b = b\n",
    "    prev_weights = weights\n",
    "    b,weights = update_parameters(X, Y, Y_hat, prev_b, prev_weights, learning_rate)\n",
    "    \n",
    "    if(iter_num%10==0):\n",
    "      gd_iterations_df.loc[result_idx] = [iter_num,this_cost]\n",
    "      result_idx=result_idx+1\n",
    "\n",
    "    iter_num +=1\n",
    "  \n",
    "  print(f'Final Bias: {b}, Weights: {weights}')\n",
    "  return gd_iterations_df, b, weights\n",
    "\n",
    "gd_iterations_df, b, weights = run_gradient_descent(X,Y,learning_rate=0.01,num_iterations=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iteration</th>\n",
       "      <th>cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.783617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.553886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.402384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30.0</td>\n",
       "      <td>0.302195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40.0</td>\n",
       "      <td>0.235767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   iteration      cost\n",
       "0        0.0  0.783617\n",
       "1       10.0  0.553886\n",
       "2       20.0  0.402384\n",
       "3       30.0  0.302195\n",
       "4       40.0  0.235767"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gd_iterations_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_basics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
